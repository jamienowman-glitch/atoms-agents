INFO:crewai.cli.config:Using config path: /Users/jaynowman/.config/crewai/settings.json
INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials
INFO:runtime.bedrock.client:Invoking Bedrock Convey API for model: anthropic.claude-3-haiku-20240307-v1:0
ERROR:runtime.bedrock.client:Bedrock ClientError: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens per day, please wait before trying again.
INFO:runtime.bedrock.client:Invoking Bedrock Convey API for model: meta.llama3-8b-instruct-v1:0
ERROR:crewai.utilities.llm_utils:Error instantiating LLM from unknown object type: Error importing native provider: OPENAI_API_KEY is required
Starting LangGraph Orchestration...
--> Running Step 1: Intern (Bedrock)
--> Running Fork B: English Debate (AutoGen)
--> Running Fork A: Spanish Team (CrewAI)
FAIL: CrewAI Runtime Error: Error importing native provider: OPENAI_API_KEY is required
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/crewai/llm.py", line 404, in __new__
    native_class(model=model_string, provider=provider, **kwargs_copy),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/crewai/llms/providers/openai/completion.py", line 97, in __init__
    client_config = self._get_client_params()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/crewai/llms/providers/openai/completion.py", line 134, in _get_client_params
    raise ValueError("OPENAI_API_KEY is required")
ValueError: OPENAI_API_KEY is required

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/_runner.py", line 258, in tick
    _panic_or_proceed(
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/_runner.py", line 520, in _panic_or_proceed
    raise exc
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/_executor.py", line 80, in done
    task.result()
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jaynowman/dev/northstar-core/scripts/run_youtube_multiframework_test.py", line 277, in node_spanish_team
    raise e
  File "/Users/jaynowman/dev/northstar-core/scripts/run_youtube_multiframework_test.py", line 241, in node_spanish_team
    result = adapter._run_generic_flow(CREW_CARD_PATH, input_payload, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jaynowman/dev/northstar-core/runtime/crewai/adapter.py", line 176, in _run_generic_flow
    crew_agents[agent_path] = Agent(
                              ^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pydantic/main.py", line 253, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/crewai/agent/internal/meta.py", line 57, in post_init_setup_with_extensions
    result = original_func(self)
             ^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/crewai/agent/core.py", line 233, in post_init_setup
    self.llm = create_llm(self.llm)
               ^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/crewai/utilities/llm_utils.py", line 66, in create_llm
    raise e
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/crewai/utilities/llm_utils.py", line 53, in create_llm
    return LLM(
           ^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/crewai/llm.py", line 409, in __new__
    raise ImportError(f"Error importing native provider: {e}") from e
ImportError: Error importing native provider: OPENAI_API_KEY is required
During task with name 'spanish_team' and id '815443b4-14a4-99b5-33c2-a4087b095491'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/jaynowman/dev/northstar-core/scripts/run_youtube_multiframework_test.py", line 429, in <module>
    run_test(args.input)
  File "/Users/jaynowman/dev/northstar-core/scripts/run_youtube_multiframework_test.py", line 399, in run_test
    final_state = app.invoke({"youtube_ideas": []})
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/main.py", line 2579, in stream
    with SyncPregelLoop(
         ^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/_loop.py", line 1138, in __exit__
    return self.stack.__exit__(exc_type, exc_value, traceback)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py", line 610, in __exit__
    raise exc_details[1]
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py", line 595, in __exit__
    if cb(*exc_details):
       ^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/_executor.py", line 107, in __exit__
    concurrent.futures.wait(pending)
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py", line 305, in wait
    waiter.event.wait(timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py", line 655, in wait
    signaled = self._cond.wait(timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py", line 355, in wait
    waiter.acquire()
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/crewai/telemetry/telemetry.py", line 206, in handler
    original_handler(signum, frame)
KeyboardInterrupt
ERROR:runtime.bedrock.client:Bedrock ClientError: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens, please wait before trying again.
INFO:runtime.bedrock.client:Invoking Bedrock Convey API for model: meta.llama3-8b-instruct-v1:0
ERROR:runtime.bedrock.client:Bedrock ClientError: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens, please wait before trying again.
INFO:runtime.bedrock.client:Invoking Bedrock Convey API for model: anthropic.claude-3-haiku-20240307-v1:0
ERROR:runtime.bedrock.client:Bedrock ClientError: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens per day, please wait before trying again.
INFO:runtime.bedrock.client:Invoking Bedrock Convey API for model: meta.llama3-8b-instruct-v1:0
ERROR:runtime.bedrock.client:Bedrock ClientError: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens, please wait before trying again.
INFO:runtime.bedrock.client:Invoking Bedrock Convey API for model: meta.llama3-8b-instruct-v1:0
ERROR:runtime.bedrock.client:Bedrock ClientError: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens, please wait before trying again.
INFO:runtime.bedrock.client:Invoking Bedrock Convey API for model: anthropic.claude-3-haiku-20240307-v1:0
ERROR:runtime.bedrock.client:Bedrock ClientError: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens per day, please wait before trying again.
INFO:runtime.bedrock.client:Invoking Bedrock Convey API for model: meta.llama3-8b-instruct-v1:0
ERROR:runtime.bedrock.client:Bedrock ClientError: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens, please wait before trying again.
INFO:runtime.bedrock.client:Invoking Bedrock Convey API for model: meta.llama3-8b-instruct-v1:0
ERROR:runtime.bedrock.client:Bedrock ClientError: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens, please wait before trying again.
INFO:runtime.bedrock.client:Invoking Bedrock Convey API for model: anthropic.claude-3-haiku-20240307-v1:0
ERROR:runtime.bedrock.client:Bedrock ClientError: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens per day, please wait before trying again.
INFO:runtime.bedrock.client:Invoking Bedrock Convey API for model: anthropic.claude-3-haiku-20240307-v1:0
ERROR:runtime.bedrock.client:Bedrock ClientError: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens per day, please wait before trying again.
